{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087e262d",
   "metadata": {},
   "source": [
    "## Aim\n",
    "#### Context\n",
    "We plan to create a strkfarm managed ETH/wstETH strategy on Ekubo. We need data analysis of past data to suggest LP parameters to manage investment with max profit\n",
    "End usage: We will be providing certain liquidity to this pool in the suggested range and we will also rebalance the position from time to time to maintain maximum fee output while keeping impermanent loss less\n",
    "#### Methodology\n",
    "Divide total available liquidity and swaps data into two parts: 70-30. 70% being used for training and optimisation, 30% used for testing the result\n",
    "#### Expected output\n",
    "Analyse the liquidity and swaps data of ETH/wstETH pool with best TVL\n",
    "Suggest logic for configuring lower & upper ticks for adding liquidity along with conditions to trigger rebalance\n",
    "Show strategy performance on the test data\n",
    "_\n",
    "\n",
    "⚠️ Note: Overfitting must be avoided. Do whatever optimisations u want on training data, once u run test on test data, share the result as it is. Do not optimise on test data.\n",
    "\n",
    "## Detailed methodology\n",
    "1. Install starknet.py to read events from ekubo using !pip install starknet.py (https://starknetpy.readthedocs.io/en/latest/account_creation.html)\n",
    "2. Key concepts of ekubo: https://docs.ekubo.org/about-ekubo/key-concepts\n",
    "3. Ekubo protocol, PositionUpdated and swap event's contract addresses are found through this. https://app.ekubo.org/charts/wstETH/ETH\n",
    "4. Block number in which ekubo protocol has been created is found by looking at the \"Ekubo positions NFT\" the token address of this nft is obtained by looking at the transfer event preceding or succeeding the add liquidity event https://voyager.online/event/669266_158_2\n",
    "https://voyager.online/tx/0x14cd53e2a6836e77da41706d4c6f0d07749c561acc3c52cd344fcc1ff920316\n",
    "4. The value of pool fee and tick spacing is taken for the pool with highest TVL https://app.ekubo.org/charts/wstETH/ETH\n",
    "5. To identify the notation in which pool fee and tick spacing are written refer to https://docs.ekubo.org/integration-guides/reference/reading-pool-price\n",
    "6. Filtered events are then divided into 70% for training and 30% for testing. \n",
    "7. The training sample is used for simulating investment for different liquidity ranges and rebalance ranges. To identify the right range for liquidity and rebalancing. \n",
    "8. a fixed liquidity is taken for now and the fee is not computed as percentage. Once the initial testing is done and the formulae is verified, will make further changes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c795f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install starknet.py\n",
    "\n",
    "# Python standard imports\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# External library imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from statistics import median\n",
    "from starknet_py.contract import Contract\n",
    "from starknet_py.net.account.account import Account\n",
    "from starknet_py.net.full_node_client import FullNodeClient\n",
    "from starknet_py.net.models.chains import StarknetChainId\n",
    "from starknet_py.net.signer.stark_curve_signer import KeyPair\n",
    "import yfinance as yf\n",
    "\n",
    "# Internal imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fc7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ekubo contract address\n",
    "contract_address = '0x00000005dd3d2f4429af886cd1a3b08289dbcea99a294197e9eb43b0e0325b4b' # ekubo\n",
    "event_key_position_updated = ['0x3a7adca3546c213ce791fabf3b04090c163e419c808c9830fb343a4a395946e'] # for PositionUpdated event\n",
    "event_key_swap = ['0x157717768aca88da4ac4279765f09f4d0151823d573537fbbeb950cdbd9a870'] #for swapped event\n",
    "from_block= 655177 #165388 # beginning of ekubo protocol  \n",
    "to_block=671277#\"latest\" # 669044\n",
    "# Creates an instance of account which is already deployed\n",
    "# Account using transaction version = 1 (has __validate__ function)\n",
    "# client = FullNodeClient(node_url=\"https://starknet-mainnet.infura.io/v3/9c1398098092415980ad945d193fe32d\")\n",
    "client = FullNodeClient(node_url=\"https://starknet-mainnet.public.blastapi.io\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pool keys\n",
    "# pool_fee = 0.001 # in %\n",
    "# tick_spacing = 0.002 # in %\n",
    "\n",
    "# pool_fee_touse = 3402823669209384797702963685910118\n",
    "# print(int(pool_fee_touse))\n",
    "# tick_spacing_touse = math.ceil(math.log(1+tick_spacing/100) / math.log(1.000001))\n",
    "# print(tick_spacing_touse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28a587cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402823669209384797702963685910118\n",
      "20\n",
      "No event found in blocks 615403 to 625402, searching next range...\n",
      "No event found in blocks 625403 to 635402, searching next range...\n",
      "No event found in blocks 635403 to 645402, searching next range...\n",
      "Event satisfying the condition found at block 655177 (Event No: 10801)\n"
     ]
    }
   ],
   "source": [
    "# start_block = 615403\n",
    "# block_chunk_size = 10000\n",
    "\n",
    "# # This is the search condition\n",
    "# def search_condition(event):\n",
    "#     data = event.data\n",
    "#     try:\n",
    "#         # Check for the first condition\n",
    "#         if (hex(data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\") and \\\n",
    "#            (hex(data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\") and \\\n",
    "#            (data[3] == pool_fee_touse) and \\\n",
    "#            (data[4] == tick_spacing_touse):\n",
    "#             return True\n",
    "        \n",
    "#         # Check for the invalid order condition\n",
    "#         elif (hex(data[1]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\") and \\\n",
    "#              (hex(data[2]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\"):\n",
    "#             raise Exception(\"invalid order\")\n",
    "    \n",
    "#     except IndexError as e:\n",
    "#         print(f\"Error while checking event data: {e}\")\n",
    "    \n",
    "#     return False\n",
    "\n",
    "# while True:\n",
    "#     # Define the range for the block search\n",
    "#     from_block = start_block\n",
    "#     to_block = start_block + block_chunk_size - 1\n",
    "\n",
    "#     try:\n",
    "#         # Fetch the events within the current block range\n",
    "#         events_response_positions_updated = await client.get_events(\n",
    "#             address=contract_address,\n",
    "#             keys=[event_key_position_updated],  # for PositionUpdated event\n",
    "#             from_block_number=from_block,\n",
    "#             to_block_number=to_block,\n",
    "#             follow_continuation_token=True,\n",
    "#             chunk_size=47,\n",
    "#         )\n",
    "        \n",
    "#         # Check if any event satisfies the condition\n",
    "#         found_event = False\n",
    "#         for event_no, event in enumerate(events_response_positions_updated.events):\n",
    "#             if search_condition(event):  # Apply the condition to each event\n",
    "#                 print(f\"Event satisfying the condition found at block {event.block_number} (Event No: {event_no})\")\n",
    "#                 found_event = True\n",
    "#                 break\n",
    "        \n",
    "#         if found_event:\n",
    "#             break  # Exit the loop if an event was found\n",
    "        \n",
    "#         # If no event was found, move to the next chunk of blocks\n",
    "#         start_block += block_chunk_size\n",
    "#         print(f\"No event found in blocks {from_block} to {to_block}, searching next range...\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while fetching events: {e}\")\n",
    "#         break  # Exit the loop if an error occurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f16b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len 565\n",
      "found EmittedEvent(from_address=158098919692956613592021320609952044916245725306097615271255138786123, keys=[1653201459205670538619725765890364513302126541856407219635220342091629827182], data=[1301608360075471435988652873011016112527098238822505666695223302941012672615, 1886212889629631188189497155848883534738756148921111726686756987927630157522, 2087021424722619777119509474943472645767659996348769578120564519014510906823, 3402823669209384797702963685910118, 20, 0, 634500, 158280, 0, 158460, 0, 27408128235124552785321, 0, 0, 0, 2670000000000000000, 0], transaction_hash=2879145539418839403171763982604352401380370371521015479181609416093330785856, block_hash=1007256769720868385100059786946035728971940593564070340067263501679755643489, block_number=655177)\n",
      "Event satisfying the condition found at block 655177 (Event No: 10801)\n"
     ]
    }
   ],
   "source": [
    "# from_block= 165388 # beginning of ekubo protocol  \n",
    "# to_block= \"latest\" # 669044\n",
    "# event_key_pool_initialized = \"0x25ccf80ee62b2ca9b97c76ccea317c7f450fd6efb6ed6ea56da21d7bb9da5f1\"\n",
    "# events_response_pool_initialized = await client.get_events(\n",
    "#     address = contract_address,\n",
    "#     keys = [[event_key_pool_initialized]], # for swap event\n",
    "#     from_block_number = from_block,\n",
    "#     to_block_number = to_block,\n",
    "#     follow_continuation_token=True,\n",
    "#     chunk_size=47,\n",
    "# )\n",
    "# print(\"len\", len(events_response_pool_initialized.events))\n",
    "\n",
    "# # This is the search condition extracted from your logic\n",
    "# def search_condition(event):\n",
    "#     data = event.data\n",
    "#     try:\n",
    "#         # Check for the first condition\n",
    "#         if (hex(data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\") and \\\n",
    "#            (hex(data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\") and \\\n",
    "#            (data[3] == pool_fee_touse) and \\\n",
    "#            (data[4] == tick_spacing_touse):\n",
    "#             print(\"found\", event)\n",
    "#             return True\n",
    "        \n",
    "#         # Check for the invalid order condition\n",
    "#         elif (hex(data[1]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\") and \\\n",
    "#              (hex(data[2]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\"):\n",
    "#             raise Exception(\"invalid order\")\n",
    "    \n",
    "#     except IndexError as e:\n",
    "#         print(f\"Error while checking event data: {e}\")\n",
    "    \n",
    "#     return False\n",
    "\n",
    "#  # Check if any event satisfies the condition\n",
    "# found_event = False\n",
    "# for event_no, event in enumerate(events_response_positions_updated.events):\n",
    "#     if search_condition(event):  # Apply the condition to each event\n",
    "#         print(f\"Event satisfying the condition found at block {event.block_number} (Event No: {event_no})\")\n",
    "#         found_event = True\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dd42de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25192\n"
     ]
    }
   ],
   "source": [
    "# events_response_positions_updated = await client.get_events(\n",
    "#     address = contract_address,\n",
    "#     keys = [event_key_position_updated], # for PositionUpdated event\n",
    "#     from_block_number = from_block,\n",
    "#     to_block_number = to_block,\n",
    "#     follow_continuation_tokaen=True,\n",
    "#     chunk_size=47,\n",
    "# )\n",
    "# print(len(events_response_positions_updated.events))\n",
    "\n",
    "\n",
    "# # Save the entire events_response_positions_updated object to a file\n",
    "# with open('events_response_positions_updated.pkl', 'wb') as f:\n",
    "#     pickle.dump(events_response_positions_updated, f)\n",
    "\n",
    "# print(\"Events data saved to events_response_positions_updated.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badc481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data loaded successfully\n",
      "EmittedEvent(from_address=158098919692956613592021320609952044916245725306097615271255138786123, keys=[1653201459205670538619725765890364513302126541856407219635220342091629827182], data=[1301608360075471435988652873011016112527098238822505666695223302941012672615, 2087021424722619777119509474943472645767659996348769578120564519014510906823, 2368576823837625528275935341135881659748932889268308403712618244410713532584, 0, 1001, 0, 0, 88722634, 1, 88722634, 0, 0, 0, 0, 0, 0, 0], transaction_hash=3380792800644086123602274049313571131378918353183444763251013603515006644394, block_hash=1007256769720868385100059786946035728971940593564070340067263501679755643489, block_number=655177)\n"
     ]
    }
   ],
   "source": [
    "# Load the events_response_positions_updated object from a file\n",
    "with open('events_response_positions_updated.pkl', 'rb') as f:\n",
    "    events_response_positions_updated = pickle.load(f)\n",
    "\n",
    "print(\"Events data loaded successfully\")\n",
    "print((events_response_positions_updated.events[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba3eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed with error: \n",
      "Retrying in 5 seconds...\n",
      "Attempt 2 failed with error: \n",
      "Retrying in 5 seconds...\n",
      "Attempt 3 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 4 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 5 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 6 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 7 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 8 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 9 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 10 failed with error: Cannot connect to host starknet-mainnet.public.blastapi.io:443 ssl:default [getaddrinfo failed]\n",
      "Retrying in 5 seconds...\n",
      "Attempt 11 failed with error: Client failed with code 429. Message: {\"jsonrpc\": \"2.0\", \"id\": 0, \"error\": {\"code\": -32097, \"message\": \"Rate limit reached\"}}.\n",
      "Retrying in 5 seconds...\n",
      "Attempt 12 failed with error: Client failed with code 429. Message: {\"jsonrpc\": \"2.0\", \"id\": 0, \"error\": {\"code\": -32097, \"message\": \"Rate limit reached\"}}.\n",
      "Retrying in 5 seconds...\n",
      "Attempt 13 failed with error: Client failed with code 429. Message: {\"jsonrpc\": \"2.0\", \"id\": 0, \"error\": {\"code\": -32097, \"message\": \"Rate limit reached\"}}.\n",
      "Retrying in 5 seconds...\n",
      "Attempt 14 failed with error: Client failed with code 429. Message: {\"jsonrpc\": \"2.0\", \"id\": 0, \"error\": {\"code\": -32097, \"message\": \"Rate limit reached\"}}.\n",
      "Retrying in 5 seconds...\n",
      "Attempt 15 failed with error: Client failed with code 502. Message: <html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ".\n",
      "Retrying in 5 seconds...\n",
      "Successfully retrieved 1658212 events in this attempt\n",
      "Total events retrieved so far: 1658212\n",
      "Events data saved to events_response_swap.pkl\n"
     ]
    }
   ],
   "source": [
    "# max_retries = 50\n",
    "# retry_delay = 5  # seconds\n",
    "# attempts = 0\n",
    "# total_retrieved_events = 0  # Accumulator to track the total number of events retrieved\n",
    "\n",
    "# events_response_swap = None\n",
    "\n",
    "# while attempts < max_retries:\n",
    "#     try:\n",
    "#         events_response_swap = await client.get_events(\n",
    "#             address=contract_address,\n",
    "#             keys=[event_key_swap],  # for swap event\n",
    "#             from_block_number=from_block,\n",
    "#             to_block_number=to_block,\n",
    "#             follow_continuation_token=True,\n",
    "#             chunk_size=47,\n",
    "#         )\n",
    "        \n",
    "#         # Update total retrieved events\n",
    "#         events_retrieved = len(events_response_swap.events)\n",
    "#         total_retrieved_events += events_retrieved\n",
    "        \n",
    "#         # Print how many events were retrieved this time and the total so far\n",
    "#         print(f\"Successfully retrieved {events_retrieved} events in this attempt\")\n",
    "#         print(f\"Total events retrieved so far: {total_retrieved_events}\")\n",
    "        \n",
    "#         break  # Exit loop after successful retrieval\n",
    "#     except Exception as e:\n",
    "#         attempts += 1\n",
    "#         print(f\"Attempt {attempts} failed with error: {e}\")\n",
    "#         if attempts < max_retries:\n",
    "#             print(f\"Retrying in {retry_delay} seconds...\")\n",
    "#             time.sleep(retry_delay)\n",
    "#         else:\n",
    "#             print(\"Max retries reached. Exiting.\")\n",
    "#             raise\n",
    "            \n",
    "# # Save the entire events_response_positions_updated object to a file\n",
    "# with open('events_response_swap.pkl', 'wb') as f:\n",
    "#     pickle.dump(events_response_swap, f)\n",
    "\n",
    "# print(\"Events data saved to events_response_swap.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configuration variables\n",
    "# max_retries = 50\n",
    "# retry_delay = 5  # seconds\n",
    "# attempts = 0\n",
    "# total_retrieved_events = 0  # Accumulator to track the total number of events retrieved\n",
    "# chunk_size = 1000  # Number of blocks to retrieve per iteration\n",
    "\n",
    "# events_response_swap = None\n",
    "# current_from_block = from_block\n",
    "# combined_events2 = []  # List to store all retrieved events\n",
    "\n",
    "# while current_from_block <= to_block:\n",
    "#     attempts = 0\n",
    "#     while attempts < max_retries:\n",
    "#         try:\n",
    "#             # Retrieve events for the current chunk of blocks\n",
    "#             events_response_swap = await client.get_events(\n",
    "#                 address=contract_address,\n",
    "#                 keys=[event_key_swap],  # for swap event\n",
    "#                 from_block_number=current_from_block,\n",
    "#                 to_block_number=min(current_from_block + chunk_size - 1, to_block),\n",
    "#                 follow_continuation_token=True,\n",
    "#                 chunk_size=47,  # Adjust chunk_size if necessary for API constraints\n",
    "#             )\n",
    "            \n",
    "#             # Update total retrieved events\n",
    "#             events_retrieved = len(events_response_swap.events)\n",
    "#             total_retrieved_events += events_retrieved\n",
    "            \n",
    "#             # Print how many events were retrieved this time and the total so far\n",
    "#             print(f\"Successfully retrieved {events_retrieved} events for blocks {current_from_block} to {min(current_from_block + chunk_size - 1, to_block)}\")\n",
    "#             print(f\"Total events retrieved so far: {total_retrieved_events}\")\n",
    "            \n",
    "#             # Append the retrieved events to the combined list\n",
    "#             combined_events2.extend(events_response_swap)\n",
    "            \n",
    "#             # Update the block range for the next iteration\n",
    "#             current_from_block += chunk_size\n",
    "            \n",
    "#             # Exit the retry loop since this attempt was successful\n",
    "#             break\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             attempts += 1\n",
    "#             print(f\"Attempt {attempts} failed with error: {e}\")\n",
    "#             if attempts < max_retries:\n",
    "#                 print(f\"Retrying in {retry_delay} seconds...\")\n",
    "#                 time.sleep(retry_delay)\n",
    "#             else:\n",
    "#                 print(\"Max retries reached. Exiting.\")\n",
    "#                 raise\n",
    "\n",
    "# # Save the combined events to a single file after processing all blocks\n",
    "# final_filename = 'combined_events_response_swap2.pkl'\n",
    "# with open(final_filename, 'wb') as f:\n",
    "#     pickle.dump(combined_events2, f)\n",
    "# print(f\"Combined events data saved to {final_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56c6888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data loaded successfully\n",
      "1738080\n"
     ]
    }
   ],
   "source": [
    "# Load the events_response_swap object from a file\n",
    "with open('combined_events_response_swap.pkl', 'rb') as f:\n",
    "    combined_events_response_swap = pickle.load(f)\n",
    "print(\"Events data loaded successfully\")\n",
    "\n",
    "print(len(combined_events_response_swap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1924924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events data loaded successfully\n",
      "                                        from_address  \\\n",
      "0  1580989196929566135920213206099520449162457253...   \n",
      "1  1580989196929566135920213206099520449162457253...   \n",
      "2  1580989196929566135920213206099520449162457253...   \n",
      "3  1580989196929566135920213206099520449162457253...   \n",
      "4  1580989196929566135920213206099520449162457253...   \n",
      "\n",
      "                                                keys  \\\n",
      "0  6068116598133324338764937091720144931722643757...   \n",
      "1  6068116598133324338764937091720144931722643757...   \n",
      "2  6068116598133324338764937091720144931722643757...   \n",
      "3  6068116598133324338764937091720144931722643757...   \n",
      "4  6068116598133324338764937091720144931722643757...   \n",
      "\n",
      "                                    transaction_hash  \\\n",
      "0  5379951863121538683099002174430011598502365039...   \n",
      "1  5379951863121538683099002174430011598502365039...   \n",
      "2  5379951863121538683099002174430011598502365039...   \n",
      "3  4855896733655157058425204165595320457715756741...   \n",
      "4  4855896733655157058425204165595320457715756741...   \n",
      "\n",
      "                                          block_hash  block_number  \\\n",
      "0  1007256769720868385100059786946035728971940593...        655177   \n",
      "1  1007256769720868385100059786946035728971940593...        655177   \n",
      "2  1007256769720868385100059786946035728971940593...        655177   \n",
      "3  1007256769720868385100059786946035728971940593...        655177   \n",
      "4  1007256769720868385100059786946035728971940593...        655177   \n",
      "\n",
      "                                              locker  \\\n",
      "0  1878172929613570324457239593384623395652998589...   \n",
      "1  1878172929613570324457239593384623395652998589...   \n",
      "2  1878172929613570324457239593384623395652998589...   \n",
      "3  1951224604049798639815629089492514906598247071...   \n",
      "4  1951224604049798639815629089492514906598247071...   \n",
      "\n",
      "                                              token0  \\\n",
      "0  2087021424722619777119509474943472645767659996...   \n",
      "1  2087021424722619777119509474943472645767659996...   \n",
      "2  2087021424722619777119509474943472645767659996...   \n",
      "3  2009894490435840142178314390393166646092438090...   \n",
      "4  2009894490435840142178314390393166646092438090...   \n",
      "\n",
      "                                              token1  \\\n",
      "0  2368576823837625528275935341135881659748932889...   \n",
      "1  2368576823837625528275935341135881659748932889...   \n",
      "2  2368576823837625528275935341135881659748932889...   \n",
      "3  2368576823837625528275935341135881659748932889...   \n",
      "4  2087021424722619777119509474943472645767659996...   \n",
      "\n",
      "                                    fee  tickspacing  ... skip_ahead  \\\n",
      "0  170141183460469235273462165868118016         1000  ...        100   \n",
      "1  170141183460469235273462165868118016         1000  ...        100   \n",
      "2  170141183460469235273462165868118016         1000  ...        100   \n",
      "3  170141183460469235273462165868118016         1000  ...          0   \n",
      "4   34028236692093847977029636859101184          200  ...          0   \n",
      "\n",
      "                 amount0  amount0_bool             amount1 amount1_bool  \\\n",
      "0     737888330085366722             0          2267658441            1   \n",
      "1      78955167492407893             0           242546697            1   \n",
      "2      18531231477828963             0            56924415            1   \n",
      "3  954241269037120886423             1           486023343            0   \n",
      "4  954241269037120886423             0  157459595364778867            1   \n",
      "\n",
      "                        sqrt_ratio_after sqrt_ratio_after_bool tick_after  \\\n",
      "0    18865301695958862243241493346127037                     0   19600424   \n",
      "1    18864580112641227103427006813131749                     0   19600500   \n",
      "2    18864410760888647462504313135679859                     0   19600518   \n",
      "3      242882341605009644724906088229414                     0   28305433   \n",
      "4  4371359385846432018201934405060718160                     0    8709408   \n",
      "\n",
      "   tick_after_bool             liquidity_after  \n",
      "0                1          114379534964441556  \n",
      "1                1          114379534964441556  \n",
      "2                1          114379534964441556  \n",
      "3                1          892612643854897266  \n",
      "4                1  22965159332619781033465020  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# # Load the events_response_swap object from a file\n",
    "# with open('combined_events_response_swap.pkl', 'rb') as f:\n",
    "#     combined_events_response_swap = pickle.load(f)\n",
    "# print(\"Events data loaded successfully\")\n",
    "\n",
    "# swap_events_ekubo_df =  pd.DataFrame(combined_events_response_swap)\n",
    "# swap_events_ekubo_df['keys'] = swap_events_ekubo_df['keys'].apply(lambda x: x[0] if isinstance(x, list) and len(x) > 0 else x)\n",
    "\n",
    "# data_column_names_swap = ['locker', 'token0', 'token1', 'fee', 'tickspacing', 'extension', 'amount', 'amount_bool', 'is_token1', 'sqrt_ratio_limit', \n",
    "#      'sqrt_ratio_limit_bool', 'skip_ahead', 'amount0','amount0_bool', 'amount1', 'amount1_bool', 'sqrt_ratio_after',\n",
    "#     'sqrt_ratio_after_bool', 'tick_after', 'tick_after_bool', 'liquidity_after']\n",
    "\n",
    "    \n",
    "# # Assuming df is your DataFrame and 'data' is the column with arrays of 17 elements\n",
    "# data_split = pd.DataFrame(swap_events_ekubo_df['data'].tolist(), columns=data_column_names_swap)\n",
    "\n",
    "# # Concatenating the new columns back to the original DataFrame\n",
    "# swap_events_ekubo_df = pd.concat([swap_events_ekubo_df, data_split], axis=1)\n",
    "\n",
    "# # Dropping the original 'data' column if you don't need it anymore\n",
    "# swap_events_ekubo_df = swap_events_ekubo_df.drop(columns=['data'])\n",
    "\n",
    "# # Display the modified DataFrame\n",
    "# print(swap_events_ekubo_df.head())\n",
    "\n",
    "# # filename = f'swap_events_ekubo_from_{from_block}_to_{to_block}.parquet'\n",
    "\n",
    "\n",
    "# # Save DataFrame as Feather file\n",
    "# swap_events_ekubo_df.to_feather(f'swap_events_ekubo_from_{from_block}_to_{to_block}.feather')\n",
    "\n",
    "\n",
    "# # # Convert all columns with large integers to float\n",
    "# # for col in events_response_swap_df.columns:\n",
    "# #     if pd.api.types.is_integer_dtype(events_response_swap_df[col]):\n",
    "# #         # Convert to float if any value exceeds 64-bit integer limit\n",
    "# #         if events_response_swap_df[col].max() > (2**63 - 1):\n",
    "# #             events_response_swap_df[col] = events_response_swap_df[col].astype(str)\n",
    "\n",
    "# # # Save the DataFrame as a Parquet file\n",
    "# # swap_events_ekubo_df.to_parquet(filename, engine='pyarrow', index=False)\n",
    "\n",
    "# # print(\"Data saved successfully in Parquet format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43a5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing values from the website \n",
    "pool_fee = 0.001  # in %\n",
    "tick_spacing = 0.002  # in %\n",
    "\n",
    "# Constants to use\n",
    "pool_fee_touse = 3402823669209384797702963685910118\n",
    "tick_spacing_touse = math.ceil(math.log(1 + tick_spacing / 100) / math.log(1.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef26a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store valid events\n",
    "valid_events_positions = []\n",
    "valid_events_swap = []\n",
    "\n",
    "# Processing positions updated events\n",
    "for event_no in range(len(events_response_positions_updated.events)):\n",
    "    event_data = events_response_positions_updated.events[event_no].data\n",
    "    \n",
    "    # Check for the first condition\n",
    "    if (hex(event_data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "        hex(event_data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\" and \\\n",
    "        event_data[3] == pool_fee_touse and \\\n",
    "        event_data[4] == tick_spacing_touse):\n",
    "        valid_events_positions.append(event_data)  # Save the valid event data\n",
    "    \n",
    "    # Check for invalid order condition\n",
    "    elif (hex(event_data[1]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "          hex(event_data[2]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\"):\n",
    "        \n",
    "        raise Exception(\"invalid order\")\n",
    "\n",
    "# Processing swap events\n",
    "for event_no_swap in range(len(combined_events_response_swap)):\n",
    "    event_data = combined_events_response_swap[event_no_swap].data\n",
    "    \n",
    "    # Check for the first condition\n",
    "    if (hex(event_data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "        hex(event_data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\" and \\\n",
    "        event_data[3] == pool_fee_touse and \\\n",
    "        event_data[4] == tick_spacing_touse):\n",
    "        valid_events_swap.append(event_data)  # Save the valid event data\n",
    "    \n",
    "    # Check for invalid order condition\n",
    "    elif (hex(event_data[1]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "          hex(event_data[2]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\"):\n",
    "        raise Exception(\"invalid order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee36116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "20248\n"
     ]
    }
   ],
   "source": [
    "print(len(valid_events_positions))\n",
    "print(len(valid_events_swap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96078130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bool_to_sign(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x == 1:\n",
    "        return -1\n",
    "    else:\n",
    "        raise Exception(\"invalid input\")\n",
    "\n",
    "ekubo_eth_weth_liquidity_data = []\n",
    "ekubo_eth_weth_swap_data = []\n",
    "\n",
    "for event_no in range(len(events_response_positions_updated.events)):\n",
    "    event_data = {\n",
    "        'block_number': events_response_positions_updated.events[event_no].block_number,\n",
    "        'transaction_hash': events_response_positions_updated.events[event_no].transaction_hash,  \n",
    "        'delta_liquidity': events_response_positions_updated.events[event_no].data[11]*bool_to_sign(events_response_positions_updated.events[event_no].data[12]),\n",
    "        'tick_lower': events_response_positions_updated.events[event_no].data[7]*bool_to_sign(events_response_positions_updated.events[event_no].data[8]),\n",
    "        'tick_upper': events_response_positions_updated.events[event_no].data[9]*bool_to_sign(events_response_positions_updated.events[event_no].data[10])\n",
    "    }\n",
    "        # Check for the first condition\n",
    "    if (hex(events_response_positions_updated.events[event_no].data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "        hex(events_response_positions_updated.events[event_no].data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\" and \\\n",
    "        events_response_positions_updated.events[event_no].data[3] == pool_fee_touse and \\\n",
    "        events_response_positions_updated.events[event_no].data[4] == tick_spacing_touse):\n",
    "            ekubo_eth_weth_liquidity_data.append(event_data)\n",
    "\n",
    "        \n",
    "for event_no_swap in range(len(combined_events_response_swap)):\n",
    "    event_data = {\n",
    "        'block_number': combined_events_response_swap[event_no_swap].block_number,\n",
    "        'transaction_hash': combined_events_response_swap[event_no_swap].transaction_hash,\n",
    "        'price': 1.000001**(-combined_events_response_swap[event_no_swap].data[18] * bool_to_sign(combined_events_response_swap[event_no].data[19])),\n",
    "        'tick_id': -combined_events_response_swap[event_no_swap].data[18] * bool_to_sign(combined_events_response_swap[event_no].data[19]),\n",
    "        'liquidity_after': combined_events_response_swap[event_no_swap].data[20],\n",
    "        'amount0': combined_events_response_swap[event_no_swap].data[12] * bool_to_sign(combined_events_response_swap[event_no].data[13]), # 0 swapping +ve \n",
    "        'amount1': combined_events_response_swap[event_no_swap].data[14] * bool_to_sign(combined_events_response_swap[event_no].data[15])\n",
    "    }\n",
    "    if (hex(combined_events_response_swap[event_no_swap].data[2]) == \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" and \\\n",
    "        hex(combined_events_response_swap[event_no_swap].data[1]) == \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\" and \\\n",
    "        combined_events_response_swap[event_no_swap].data[3] == pool_fee_touse and \\\n",
    "        combined_events_response_swap[event_no_swap].data[4] == tick_spacing_touse):\n",
    "            ekubo_eth_weth_swap_data.append(event_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1024a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123100\n",
      "158440\n",
      "162969\n",
      "158443\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas DataFrame\n",
    "liquidity_df = pd.DataFrame(ekubo_eth_weth_liquidity_data)\n",
    "print(min(liquidity_df.tick_lower))\n",
    "print(min(liquidity_df.tick_upper))\n",
    "\n",
    "swap_df = pd.DataFrame(ekubo_eth_weth_swap_data)\n",
    "print(max(swap_df.tick_id))\n",
    "print(min(swap_df.tick_id))\n",
    "\n",
    "\n",
    "swap_df['fee_token1_ETH'] = (pool_fee/100 * swap_df['amount1'].abs()) / 10**18\n",
    "\n",
    "print(max(swap_df.fee_token1_ETH))\n",
    "\n",
    "# # Convert to Parquet using pyarrow\n",
    "# table = pa.Table.from_pandas(df)\n",
    "# pq.write_table(table, 'events_data.parquet')\n",
    "\n",
    "# print(\"Data saved to Parquet file successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d513668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Collect block numbers and prices from ekubo_eth_weth_swap_data\n",
    "block_price_data = [{'block_number': event['block_number'], 'price': event['price']} for event in ekubo_eth_weth_swap_data]\n",
    "\n",
    "# Step 2: Convert the collected data into a pandas DataFrame\n",
    "df = pd.DataFrame(block_price_data)\n",
    "\n",
    "# Step 3: Group by block number and calculate the median price for each block\n",
    "median_prices_df = df.groupby('block_number')['price'].median().reset_index()\n",
    "median_prices_df.columns = ['block_number', 'median_price']\n",
    "\n",
    "# Step 4: Define the functions to calculate and round tick_id from prices\n",
    "def price_to_tick_id(price):\n",
    "    return int(np.log(price) / np.log(1.000001))\n",
    "\n",
    "def round_to_tick_spacing(tick_id, tick_spacing_touse):\n",
    "    return round(tick_id / tick_spacing_touse) * tick_spacing_touse\n",
    "\n",
    "price_range_liquidity = 20\n",
    "# Step 5: Add ±5% price boundaries and convert them to tick_id\n",
    "median_prices_df['price_minus_20%'] = median_prices_df['median_price'] * (1 - (price_range_liquidity*0.01))\n",
    "median_prices_df['price_plus_20%'] = median_prices_df['median_price'] * (1 + (price_range_liquidity*0.01))\n",
    "median_prices_df['tick_id_median'] = median_prices_df['median_price'].apply(price_to_tick_id)\n",
    "median_prices_df['tick_id_minus_20%'] = median_prices_df['price_minus_20%'].apply(price_to_tick_id)\n",
    "median_prices_df['tick_id_plus_20%'] = median_prices_df['price_plus_20%'].apply(price_to_tick_id)\n",
    "\n",
    "# Step 6: Round the tick_ids to the nearest multiple of tick_spacing_touse\n",
    "tick_spacing_touse = 20  # Define tick_spacing\n",
    "median_prices_df['tick_id_minus_20%_rounded'] = median_prices_df['tick_id_minus_20%'].apply(lambda x: round_to_tick_spacing(x, tick_spacing_touse))\n",
    "median_prices_df['tick_id_plus_20%_rounded'] = median_prices_df['tick_id_plus_20%'].apply(lambda x: round_to_tick_spacing(x, tick_spacing_touse))\n",
    "\n",
    "# Step 7: Create an array of tick IDs for each block\n",
    "median_prices_df['tick_id_array'] = median_prices_df.apply(\n",
    "    lambda row: np.arange(row['tick_id_minus_20%_rounded'], row['tick_id_plus_20%_rounded'] + tick_spacing_touse, tick_spacing_touse), axis=1\n",
    ")\n",
    "\n",
    "# Step 8: Retain the necessary columns\n",
    "final_df = median_prices_df[['block_number', 'median_price', 'tick_id_median', 'tick_id_array']]\n",
    "\n",
    "# Step 9: Distribute cumulative liquidity per block\n",
    "cumulative_liquidity_per_tick = {}\n",
    "\n",
    "liquidity_per_block = []  # To store cumulative liquidity for each block\n",
    "\n",
    "for idx, row in final_df.iterrows():\n",
    "    block_number = row['block_number']\n",
    "    tick_array = row['tick_id_array']\n",
    "\n",
    "    # Initialize cumulative liquidity if not already initialized\n",
    "    if not cumulative_liquidity_per_tick:\n",
    "        cumulative_liquidity_per_tick = {tick: 0 for tick in tick_array}\n",
    "\n",
    "    # Clone the current cumulative state so that we can update it for the current block\n",
    "    current_block_liquidity = cumulative_liquidity_per_tick.copy()\n",
    "\n",
    "    # Get liquidity data for the current block only\n",
    "    liquidity_data_for_block = [event for event in ekubo_eth_weth_liquidity_data if event['block_number'] == block_number]\n",
    "    \n",
    "    # Add the current block's liquidity to the cumulative state\n",
    "    for liquidity_event in liquidity_data_for_block:\n",
    "        tick_lower = liquidity_event['tick_lower']\n",
    "        tick_upper = liquidity_event['tick_upper']\n",
    "        delta_liquidity = liquidity_event['delta_liquidity']\n",
    "        \n",
    "        # Distribute liquidity to the relevant ticks in the cumulative state\n",
    "        for tick in tick_array:\n",
    "            if tick_lower <= tick <= tick_upper:\n",
    "                current_block_liquidity[tick] += delta_liquidity\n",
    "    \n",
    "    # Update the cumulative liquidity state\n",
    "    cumulative_liquidity_per_tick = current_block_liquidity.copy()\n",
    "\n",
    "    # Store the cumulative liquidity distribution for the current block\n",
    "    liquidity_per_block.append({\n",
    "        'block_number': block_number,\n",
    "        'tick_liquidity_distribution': current_block_liquidity\n",
    "    })\n",
    "\n",
    "# # Step 10: Create a DataFrame for cumulative liquidity distribution\n",
    "# liquidity_df = pd.DataFrame(liquidity_per_block)\n",
    "\n",
    "# # Step 11: Print all non-zero cumulative liquidity ticks and their values\n",
    "# for idx, row in liquidity_df.iterrows():\n",
    "#     block_number = row['block_number']\n",
    "#     tick_liquidity_distribution = row['tick_liquidity_distribution']\n",
    "    \n",
    "#     # Filter out ticks with zero liquidity\n",
    "#     non_zero_liquidity = {tick: liquidity for tick, liquidity in tick_liquidity_distribution.items() if liquidity != 0}\n",
    "    \n",
    "#     # Print non-zero liquidity ticks\n",
    "#     print(f\"Block Number: {block_number}\")\n",
    "#     if non_zero_liquidity:\n",
    "#         for tick, liquidity in non_zero_liquidity.items():\n",
    "#             print(f\"  Tick: {tick}, Liquidity: {liquidity}\")\n",
    "#     print(\"-\" * 40)\n",
    "\n",
    "# # Step 12: Plot the cumulative liquidity distribution for the last block\n",
    "# last_block_data = liquidity_df.iloc[-1]\n",
    "# last_block_number = last_block_data['block_number']\n",
    "# last_block_tick_liquidity = last_block_data['tick_liquidity_distribution']\n",
    "\n",
    "# # Convert the tick liquidity distribution for plotting\n",
    "# ticks = list(last_block_tick_liquidity.keys())\n",
    "# liquidity = list(last_block_tick_liquidity.values())\n",
    "\n",
    "# # Plot the last block's cumulative tick liquidity distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(ticks, liquidity, color='green')\n",
    "# plt.xlabel('Tick')\n",
    "# plt.ylabel('Cumulative Liquidity')\n",
    "# plt.title(f'Cumulative Liquidity Distribution Across Ticks for Block {last_block_number}')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8866980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   block_number                                   transaction_hash  \\\n",
      "0        655177  2879145539418839403171763982604352401380370371...   \n",
      "1        655424  1279209847316592012798496238689033441847594858...   \n",
      "2        655424  2236106133222411803388378305320859355758706418...   \n",
      "3        655424  3387282097104070895993181893437770629177012930...   \n",
      "4        655424  3779414541303248423459591667090630130681763650...   \n",
      "\n",
      "            delta_liquidity  tick_lower  tick_upper  median_price  \\\n",
      "0   27408128235124552785321      158280      158460      1.171710   \n",
      "1  -99209107691145427163307      158400      158440      1.171794   \n",
      "2     262573697381870119149      158000      158800      1.171794   \n",
      "3   10990777850625690682059      158220      158860      1.171794   \n",
      "4   99205850788549541510734      158540      158580      1.171794   \n",
      "\n",
      "   tick_id_median                                      tick_id_array  \n",
      "0          158463  [-64680.0, -64660.0, -64640.0, -64620.0, -6460...  \n",
      "1          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "2          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "3          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "4          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Merge liquidity_df and final_df on block_number\n",
    "liquidity_distribution_df = pd.merge(liquidity_df, final_df, on='block_number', how='inner')\n",
    "\n",
    "# Step 2: Inspect the combined DataFrame\n",
    "print(liquidity_distribution_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e931eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Block: 666447\n",
      "Max Block: 671277\n",
      "Min Block: 655177\n",
      "Training Swap DataFrame:\n",
      "   block_number                                   transaction_hash     price  \\\n",
      "0        655177  2416157948790894051047941157778594406573451511...  1.171710   \n",
      "1        655177  2416157948790894051047941157778594406573451511...  1.171710   \n",
      "2        655179  1241404949126819184019688044659591190675013926...  1.171708   \n",
      "3        655179  1241404949126819184019688044659591190675013926...  1.171708   \n",
      "4        655179  1241404949126819184019688044659591190675013926...  1.171708   \n",
      "\n",
      "   tick_id           liquidity_after            amount0             amount1  \\\n",
      "0   158464  137703958037274544831372   2256616757779677   -2644126307134438   \n",
      "1   158464  137703958037274544831372                  0                   0   \n",
      "2   158463  137703958037274544831372  42668433630093793  -49994504035756152   \n",
      "3   158463  137703958037274544831372  21336138963323289  -25000000000000000   \n",
      "4   158463  137703958037274544831372  21334216438183549  -24997247385081083   \n",
      "\n",
      "  fee_token1_ETH  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n",
      "\n",
      "Testing Swap DataFrame:\n",
      "       block_number                                   transaction_hash  \\\n",
      "13683        666448  1903276054207653061200648579526616639866312958...   \n",
      "13684        666449  1608441755630721589754255098830551190850725439...   \n",
      "13685        666451  9931488744090905119109952418155395942826310943...   \n",
      "13686        666451  3213033526508709098246266080731316210281387800...   \n",
      "13687        666453  2077367677876820406995683185706584473581686340...   \n",
      "\n",
      "         price  tick_id             liquidity_after            amount0  \\\n",
      "13683  1.17387   160306  11346195275753762193653033  10042534198831409   \n",
      "13684  1.17387   160306  11355452824249381796219829   9591248785087431   \n",
      "13685  1.17387   160306  11355452824249381796219829  63890550968730428   \n",
      "13686  1.17387   160306  11355452824249381796219829   3836499462345422   \n",
      "13687  1.17387   160306  11355452824249381796219829    159726376328769   \n",
      "\n",
      "                  amount1 fee_token1_ETH  \n",
      "13683  -11788755094454503            0.0  \n",
      "13684  -11258999068426240            0.0  \n",
      "13685  -75000000000000000       0.000001  \n",
      "13686   -4503599627370496            0.0  \n",
      "13687    -187500000000000            0.0  \n",
      "\n",
      "Training Liquidity DataFrame:\n",
      "   block_number                                   transaction_hash  \\\n",
      "0        655177  2879145539418839403171763982604352401380370371...   \n",
      "1        655424  1279209847316592012798496238689033441847594858...   \n",
      "2        655424  2236106133222411803388378305320859355758706418...   \n",
      "3        655424  3387282097104070895993181893437770629177012930...   \n",
      "4        655424  3779414541303248423459591667090630130681763650...   \n",
      "\n",
      "            delta_liquidity  tick_lower  tick_upper  median_price  \\\n",
      "0   27408128235124552785321      158280      158460      1.171710   \n",
      "1  -99209107691145427163307      158400      158440      1.171794   \n",
      "2     262573697381870119149      158000      158800      1.171794   \n",
      "3   10990777850625690682059      158220      158860      1.171794   \n",
      "4   99205850788549541510734      158540      158580      1.171794   \n",
      "\n",
      "   tick_id_median                                      tick_id_array  \n",
      "0          158463  [-64680.0, -64660.0, -64640.0, -64620.0, -6460...  \n",
      "1          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "2          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "3          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "4          158536  [-64600.0, -64580.0, -64560.0, -64540.0, -6452...  \n",
      "\n",
      "Testing Liquidity DataFrame:\n",
      "     block_number                                   transaction_hash  \\\n",
      "321        666536  1911543264031492649671364865746270888424138935...   \n",
      "322        666743  3612697557243504901502164165821570526602030830...   \n",
      "323        666982  1023031846198601328814752678430201167139131307...   \n",
      "324        666983  1795379526864516001192759226179826164944519758...   \n",
      "325        666983  2384016552412773352303828238304857297788222934...   \n",
      "\n",
      "              delta_liquidity  tick_lower  tick_upper  median_price  \\\n",
      "321    7100366254514246602899      160020      160280      1.173852   \n",
      "322     -82531684244086087439      159720      159980      1.173859   \n",
      "323   -2157049420910909153013      160020      160380      1.173916   \n",
      "324    1738100128455342997294      160320      160760      1.173916   \n",
      "325  429510341611072721155679      160020      160040      1.173916   \n",
      "\n",
      "     tick_id_median                                      tick_id_array  \n",
      "321          160291  [-62860.0, -62840.0, -62820.0, -62800.0, -6278...  \n",
      "322          160296  [-62840.0, -62820.0, -62800.0, -62780.0, -6276...  \n",
      "323          160344  [-62800.0, -62780.0, -62760.0, -62740.0, -6272...  \n",
      "324          160344  [-62800.0, -62780.0, -62760.0, -62740.0, -6272...  \n",
      "325          160344  [-62800.0, -62780.0, -62760.0, -62740.0, -6272...  \n"
     ]
    }
   ],
   "source": [
    "# Assuming both swap_df and liquidity_distribution_df are already created\n",
    "# and contain the 'block_number' column\n",
    "\n",
    "# Calculate the maximum, minimum, and split block number\n",
    "max_block = max(swap_df['block_number'])\n",
    "min_block = min(swap_df['block_number'])\n",
    "split_block = round(min_block + (max_block - min_block) * 0.7)\n",
    "\n",
    "print(\"Split Block:\", split_block)\n",
    "print(\"Max Block:\", max_block)\n",
    "print(\"Min Block:\", min_block)\n",
    "\n",
    "# Split the data into the first 70% and the remaining 30% for both DataFrames\n",
    "# For swap_df\n",
    "train_swap_df = swap_df[swap_df['block_number'] <= split_block]\n",
    "test_swap_df = swap_df[swap_df['block_number'] > split_block]\n",
    "\n",
    "# For liquidity_distribution_df\n",
    "train_liquidity_df = liquidity_distribution_df[liquidity_distribution_df['block_number'] <= split_block]\n",
    "test_liquidity_df = liquidity_distribution_df[liquidity_distribution_df['block_number'] > split_block]\n",
    "\n",
    "# Inspect the resulting DataFrames\n",
    "print(\"Training Swap DataFrame:\")\n",
    "print(train_swap_df.head())\n",
    "print(\"\\nTesting Swap DataFrame:\")\n",
    "print(test_swap_df.head())\n",
    "\n",
    "print(\"\\nTraining Liquidity DataFrame:\")\n",
    "print(train_liquidity_df.head())\n",
    "print(\"\\nTesting Liquidity DataFrame:\")\n",
    "print(test_liquidity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize to identify range in which I should invest and when to book impermanent loss\n",
    "# Triggers to think about \n",
    "# 1. Price crosses outside of the current range: Move the range closer to the new price.\n",
    "# 2. Increased volatility: Widen the range to accommodate more price movements.\n",
    "# 3. Liquidity depletion: Reallocate liquidity if the current position is largely consumed.\n",
    "# 4. Fee accumulation: Rebalance after reaching a threshold of fees.\n",
    "# 5. Time-based rebalance: Rebalance periodically to optimize positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461e1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "    Liquidity Range (%)  Rebalance Range (%)  Net Earnings (ETH)  \\\n",
      "5                   0.6                  0.6        3.284067e-19   \n",
      "6                   0.6                  1.1        3.284067e-19   \n",
      "7                   0.6                  1.6        3.284067e-19   \n",
      "9                   1.1                  0.6        3.284067e-19   \n",
      "10                  1.1                  1.1        3.284067e-19   \n",
      "\n",
      "    Total Fees Earned (ETH)  Impermanent Loss (ETH)  \n",
      "5              3.284067e-19                     0.0  \n",
      "6              3.284067e-19                     0.0  \n",
      "7              3.284067e-19                     0.0  \n",
      "9              3.284067e-19                     0.0  \n",
      "10             3.284067e-19                     0.0  \n"
     ]
    }
   ],
   "source": [
    "# Function to convert price to tick\n",
    "def price_to_tick(price):\n",
    "    return int(math.log(price) / math.log(1.0001))\n",
    "\n",
    "# Function to calculate impermanent loss\n",
    "def impermanent_loss(price_ratio):\n",
    "    return 1 - math.sqrt((4 * price_ratio) / ((price_ratio + 1) ** 2))\n",
    "\n",
    "initial_liquidity = 10000000\n",
    "fee_percentage = 0.00001\n",
    "# Function to run the simulation for a given liquidity and rebalancing range\n",
    "def run_simulation(liquidity_range, rebalance_range):\n",
    "    initial_price = train_swap_df['price'].iloc[0]  # Initial price from the data\n",
    "    fees_earned = 0\n",
    "    impermanent_loss_total = 0\n",
    "    current_liquidity = initial_liquidity\n",
    "    \n",
    "    for swap_event in range(len(train_swap_df)):\n",
    "        current_price = train_swap_df['price'].iloc[swap_event]\n",
    "        amount_swapped = train_swap_df['amount1'].iloc[swap_event]\n",
    "        available_liquidity = train_swap_df['liquidity_after'].iloc[swap_event]\n",
    "        \n",
    "        current_tick = price_to_tick(current_price)\n",
    "        \n",
    "        # Calculate the bounds of the liquidity range (ticks)\n",
    "        liquidity_lower_bound = initial_price * (1 - liquidity_range)\n",
    "        liquidity_upper_bound = initial_price * (1 + liquidity_range)\n",
    "\n",
    "        tick_lower_bound = price_to_tick(liquidity_lower_bound)\n",
    "        tick_upper_bound = price_to_tick(liquidity_upper_bound)\n",
    "        \n",
    "        # Check if the current tick is within the range of added liquidity\n",
    "        if tick_lower_bound <= current_tick <= tick_upper_bound:\n",
    "            # Each tick has liquidity equal to the current liquidity\n",
    "            fees_earned += abs(amount_swapped) / 10**18 * fee_percentage * current_liquidity / available_liquidity\n",
    "            \n",
    "        # Check if the current price is within the rebalancing range\n",
    "        rebalance_lower_bound = initial_price * (1 - rebalance_range)\n",
    "        rebalance_upper_bound = initial_price * (1 + rebalance_range)\n",
    "        \n",
    "        if not (rebalance_lower_bound <= current_price <= rebalance_upper_bound):\n",
    "            # Price is out of rebalance range, rebalance\n",
    "            price_ratio = current_price / initial_price\n",
    "            il = impermanent_loss(price_ratio)\n",
    "            impermanent_loss_total += il\n",
    "            \n",
    "            # Update liquidity position by adding earned fees\n",
    "            current_liquidity += fees_earned\n",
    "            fees_earned = 0  # Reset fees after rebalancing\n",
    "            \n",
    "            # Reset initial price to the new price after rebalancing\n",
    "            initial_price = current_price\n",
    "            print('i')\n",
    "    \n",
    "    # Final calculation of returns\n",
    "    net_earnings = fees_earned - impermanent_loss_total\n",
    "    \n",
    "    return net_earnings, fees_earned, impermanent_loss_total\n",
    "\n",
    "# Run the simulation and generate the optimization results\n",
    "optimization_results = []\n",
    "liquidity_range_options = np.arange(0.001, 0.021, 0.005)  # Liquidity add range from 5% to 20%\n",
    "rebalance_range_options = np.arange(0.001, 0.021, 0.005)  # Rebalance range from 5% to 20%\n",
    "\n",
    "for liquidity_range in liquidity_range_options:\n",
    "    for rebalance_range in rebalance_range_options:\n",
    "        net_earnings, fees_earned, impermanent_loss_total = run_simulation(liquidity_range, rebalance_range)\n",
    "        optimization_results.append({\n",
    "            \"Liquidity Range (%)\": liquidity_range * 100,\n",
    "            \"Rebalance Range (%)\": rebalance_range * 100,\n",
    "            \"Net Earnings (ETH)\": net_earnings,\n",
    "            \"Total Fees Earned (ETH)\": fees_earned,\n",
    "            \"Impermanent Loss (ETH)\": impermanent_loss_total\n",
    "        })\n",
    "\n",
    "# Convert optimization results to a DataFrame for analysis\n",
    "optimization_df = pd.DataFrame(optimization_results)\n",
    "\n",
    "# Sort by net earnings to find the best performing combination\n",
    "optimization_df_sorted = optimization_df.sort_values(by=\"Net Earnings (ETH)\", ascending=False)\n",
    "\n",
    "# Display the top 5 performing combinations\n",
    "print(optimization_df_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify prices\n",
    "\n",
    "# Define the ticker symbols for ETH and wETH\n",
    "eth_symbol = 'ETH-USD'\n",
    "weth_symbol = 'WETH-USD'\n",
    "\n",
    "# Fetch historical data for both tokens over a given period (e.g., 1 month)\n",
    "eth_data = yf.Ticker(eth_symbol).history(period=\"1mo\")\n",
    "weth_data = yf.Ticker(weth_symbol).history(period=\"1mo\")\n",
    "\n",
    "# Align both dataframes by the same date index (merge them on the 'Date' column)\n",
    "data = pd.DataFrame({\n",
    "    'ETH Price': eth_data['Close'],\n",
    "    'wETH Price': weth_data['Close']\n",
    "})\n",
    "\n",
    "# Drop any rows with missing data (if there are any mismatched dates)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Calculate the ratio of ETH price to wETH price for each date\n",
    "data['Price Ratio (ETH/wETH)'] = data['ETH Price'] / data['wETH Price']\n",
    "\n",
    "# Determine the entire price ratio range\n",
    "min_ratio = data['Price Ratio (ETH/wETH)'].min()\n",
    "max_ratio = data['Price Ratio (ETH/wETH)'].max()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Minimum ETH/wETH Price Ratio: {min_ratio}\")\n",
    "print(f\"Maximum ETH/wETH Price Ratio: {max_ratio}\")\n",
    "\n",
    "# Optional: Plot the price ratios over time\n",
    "data['Price Ratio (ETH/wETH)'].plot(title=\"ETH/wETH Price Ratio Over Time\")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4977ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401bbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETH: \"0x49d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\" \n",
    "# wstETH: \"0x42b8f0484674ca266ac5d08e4ac6a3fe65bd3129795def2dca5c34ecc5f96d2\"\n",
    "# price = 1.0001^(tick_id or tick_value)\n",
    "    \n",
    "    \n",
    "    {'locker', 'token0', 'token1', 'fee', 'tickspacing', 'extension', 'salt', 'lower', 'lower_bool', 'upper', \n",
    "     'upper_bool', 'delta_liquidity', 'delta_liquidity_bool', 'amount0','amount0_bool', 'amount1', 'amount1_bool'}\n",
    "# For idetifying the index of \n",
    "Position_updated\n",
    "EmittedEvent(\n",
    "    from_address=158098919692956613592021320609952044916245725306097615271255138786123, \n",
    "    keys=[1653201459205670538619725765890364513302126541856407219635220342091629827182], \n",
    "    data=[locker:1301608360075471435988652873011016112527098238822505666695223302941012672615,  #0\n",
    "          poolkey: token0:2087021424722619777119509474943472645767659996348769578120564519014510906823,  #1\n",
    "          token1:2368576823837625528275935341135881659748932889268308403712618244410713532584,  #2\n",
    "          fee:170141183460469235273462165868118016,  #3\n",
    "          tickspacing:1000,  #4\n",
    "          Extension:0,  #5\n",
    "          Salt: 238207,  #6\n",
    "          lower: 88722000, 1,  #7, 8\n",
    "          Upper: 88722000, 0,  #9, 10 \n",
    "          Delta_liquidity: 24934382157, 1,  #11, 12\n",
    "          Amount0: 433198613657447, 1,  #13, 14\n",
    "          Amount1: 1433756, 1],  #15, 16\n",
    "      transaction_hash=879945867416280128092979369806709446749761821654825519062415897008764242951,\n",
    "      block_hash=2421102280480996809432903330067643765909910418548957016097347656801334531512,\n",
    "      block_number=663452)\n",
    "\n",
    "\n",
    "\n",
    "    {'locker', 'token0', 'token1', 'fee', 'tickspacing', 'extension', 'amount', 'amount_bool', 'is_token1', 'sqrt_ratio_limit', \n",
    "     'sqrt_ratio_limit_bool', 'skip_ahead', 'amount0','amount0_bool', 'amount1', 'amount1_bool', 'sqrt_ratio_after',\n",
    "    'sqrt_ratio_after_bool', 'tick_after', 'tick_after_bool', 'liquidity_after'}\n",
    "\n",
    "Swap\n",
    "EmittedEvent(\n",
    "    from_address=158098919692956613592021320609952044916245725306097615271255138786123, \n",
    "    keys=[606811659813332433876493709172014493172264375712319669538606486437773289584], \n",
    "    data=[Locker: 1951224604049798639815629089492514906598247071757934301055136774321924456550, #0\n",
    "          Poolkey: token0: 2087021424722619777119509474943472645767659996348769578120564519014510906823, #1\n",
    "          token1: 2368576823837625528275935341135881659748932889268308403712618244410713532584, #2\n",
    "          fee: 170141183460469235273462165868118016,  #3\n",
    "          tick_spacing 1000,  #4\n",
    "          Extension: 0,  #5\n",
    "          \n",
    "          Params: Amount (mag, sign) 18750000000000000, 0,  #6, 7\n",
    "          isToken1: 0,  #8\n",
    "          sqrt_ratio_limit: 15411102256202172767744790565534148, 0,  #9, 10\n",
    "          skip_ahead: 0,  #11\n",
    "          \n",
    "          Amount0: 18750000000000000, 0,  #12,13\n",
    "          Amount1: 49541253, 1, #14, 15\n",
    "          sqrt_Ratio_After: 17495541587887167702017650483399816, 0, # 16, 17\n",
    "          tick_after: 19751180, 1, #18, 19\n",
    "          liquidity_after: 59517410719957310], #20\n",
    "    transaction_hash=1028460612028350658488036399834335161397563811459669946359742869978934007182,\n",
    "    block_hash=2750810716156707596732812189537740646505960575694968173768545834980232403465, \n",
    "    block_number=668044)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a14b774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x246168c475c5ca4a9204306e73470f652f433abf5a55a6d847ea0083625d58e'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(1028460612028350658488036399834335161397563811459669946359742869978934007182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac6e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
